{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 10 мая 2021, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 10 мая, -4 балла после 08:30 17 мая, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0221, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваше решение тут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) MSE: $$  -\\frac{\\partial L(a(x_i), y_i)}{\\partial a(x_i)} = -\\frac{\\partial  (y_i - a(x_i)) ^ 2}{\\partial a(x_i)} = 2(y_i - a(x_i)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Экспоненциальный таргет: $$  -\\frac{\\partial L(a(x_i), y_i)}{\\partial a(x_i)} = -\\frac{\\partial  (exp( -a(x_i) y_i))}{\\partial a(x_i)} = y_iexp(-a(x_i)y_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Логистический таргет: $$  -\\frac{\\partial L(a(x_i), y_i)}{\\partial a(x_i)} = -\\frac{\\partial  \\log (1 + exp( -a(x_i) y_i))}{\\partial a(x_i)} = \n",
    "    \\frac{y_i}{1 +  exp(a(x_i) y_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss='mse', learning_rate=0.1, n_estimators=100, colsample=1.0, subsample=1.0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def calc_loss(self, y, a):\n",
    "        if self.loss == 'mse':\n",
    "            return 2 * (y - a)\n",
    "        elif self.loss == 'exp':\n",
    "            return y * np.exp(-y * a)\n",
    "        elif self.loss == 'log':\n",
    "            return y / (np.exp(a*y) + 1)\n",
    "    \n",
    "    def fit(self, X, y,  base_model = DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        self.info = dict()\n",
    "        total_objects = X.shape[0]\n",
    "        total_features = X.shape[1]\n",
    "        used_objects = int(np.floor(self.subsample * total_objects))\n",
    "        used_features = int(np.floor(self.colsample * total_features))\n",
    "        if init_model is not None:\n",
    "            self.init_model = init_model()\n",
    "            self.init_model.fit(X, y)\n",
    "            self.fk = self.init_model.predict(X)\n",
    "        else:\n",
    "            self.init_model = None\n",
    "            self.fk = np.ones(total_objects)/total_objects\n",
    "        for i in range(0, self.n_estimators):\n",
    "            cur_used_features = np.random.choice(total_features, used_features)\n",
    "            cur_used_objects = np.random.choice(total_objects, total_objects)\n",
    "            cur_model = base_model(*self.args, **self.kwargs)\n",
    "            used_X = X[cur_used_objects,:][:, cur_used_features]\n",
    "            used_for_pred_X = X[:,:][:, cur_used_features]\n",
    "            used_y = y[cur_used_objects]\n",
    "            used_fk = self.fk[cur_used_objects]\n",
    "            cur_los = self.calc_loss(used_y, used_fk)\n",
    "            cur_model.fit(used_X, cur_los)\n",
    "            self.fk = self.fk + self.learning_rate * cur_model.predict(used_for_pred_X)\n",
    "            self.info[i] = dict()\n",
    "            self.info[i][0] = cur_model\n",
    "            self.info[i][1] = cur_used_features\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.init_model is not None:\n",
    "            res = self.init_model.predict(X)\n",
    "        else:\n",
    "            res = np.ones(X.shape[0])/X.shape[0]\n",
    "        for i in range(len(self.info)):\n",
    "            used_X = X[:,:][:, self.info[i][1]]\n",
    "            temp = self.info[i][0].predict(used_X)\n",
    "            temp = temp * self.learning_rate\n",
    "            res = res + temp\n",
    "        return np.around(res).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "num_est = [5*i for i in np.arange(1, 11)]\n",
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c0fc61a05b4b36857b2672cfefc48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169089147286821\n",
      "0.8624515503875969\n",
      "0.8647286821705427\n",
      "0.8688953488372093\n",
      "0.8651162790697674\n",
      "0.8815891472868216\n",
      "0.870203488372093\n",
      "0.8781492248062015\n",
      "0.8775678294573643\n",
      "0.8659399224806201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results =[]\n",
    "for elem in tqdm_notebook(num_est):\n",
    "    res = 0.0\n",
    "    for train, test in skf.split(X, y):\n",
    "        my_clf1 = MyGradientBoostingClassifier(n_estimators=elem)\n",
    "        my_clf1.fit(X[train], y[train])\n",
    "        temp = my_clf1.predict(X[test])\n",
    "        res = res + accuracy_score(y[test], temp)\n",
    "    print(res/5.0)\n",
    "    results.append(res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"accuracy from n_estimators\", fontsize = 20)\n",
    "plt.xlabel(\"n_estimators\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy_score\", fontsize = 20)\n",
    "plt.plot(num_est, results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "help1 = results.index(max(results))\n",
    "best_est = num_est[help1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целях экономии времени при валидации, ограничим число n_estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_est = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['mse', 'exp','log']\n",
    "learn = [0.05, 0.1, 0.2]\n",
    "colsample = [0.5, 0.75, 1.0]\n",
    "subsample = [0.5, 0.75, 1.0]\n",
    "best_score = 0\n",
    "best_params = dict()\n",
    "best_params['loss'] = None\n",
    "best_params['learning_rate'] = None\n",
    "best_params['n_estimators'] = best_est\n",
    "best_params['colsample'] = None\n",
    "best_params['subsample'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8174418604651162   1\n",
      "0.8174418604651162\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.5, 'subsample': 0.5}\n",
      "0.831734496124031   2\n",
      "0.831734496124031\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.5, 'subsample': 0.75}\n",
      "0.8235465116279072   3\n",
      "0.831734496124031\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.5, 'subsample': 0.75}\n",
      "0.8593507751937984   4\n",
      "0.8593507751937984\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.75, 'subsample': 0.5}\n",
      "0.8551841085271319   5\n",
      "0.8593507751937984\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.75, 'subsample': 0.5}\n",
      "0.8474321705426355   6\n",
      "0.8593507751937984\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 0.75, 'subsample': 0.5}\n",
      "0.8634205426356589   7\n",
      "0.8634205426356589\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.5}\n",
      "0.8585271317829456   8\n",
      "0.8634205426356589\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.5}\n",
      "0.867296511627907   9\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8343992248062015   10\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8138565891472869   11\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8348837209302327   12\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.858624031007752   13\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8496124031007752   14\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8599806201550386   15\n",
      "0.867296511627907\n",
      "{'loss': 'mse', 'learning_rate': 0.05, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 1.0}\n",
      "0.8711240310077519   16\n",
      "0.8711240310077519\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.5}\n",
      "0.874563953488372   17\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8709786821705426   18\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.798013565891473   19\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7874031007751938   20\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7926841085271317   21\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8300872093023255   22\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8303294573643409   23\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8264534883720931   24\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.846656976744186   25\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8458333333333332   26\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8409399224806201   27\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.6484496124031007   28\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.664389534883721   29\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.6836724806201551   30\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7270348837209302   31\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7097868217054263   32\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7358527131782945   33\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7527131782945736   34\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7615310077519379   35\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.751841085271318   36\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8581395348837211   37\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8559593023255813   38\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8536337209302326   39\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8709302325581396   40\n",
      "0.874563953488372\n",
      "{'loss': 'mse', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.879796511627907   41\n",
      "0.879796511627907\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 0.75, 'subsample': 0.75}\n",
      "0.8656007751937984   42\n",
      "0.879796511627907\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 0.75, 'subsample': 0.75}\n",
      "0.8801841085271318   43\n",
      "0.8801841085271318\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.5}\n",
      "0.8825096899224805   44\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8770348837209301   45\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7840116279069768   46\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8127422480620154   47\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.801986434108527   48\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8317829457364342   49\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8450096899224807   50\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8257267441860465   51\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8434108527131784   52\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8484011627906977   53\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8523255813953489   54\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   55\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   56\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   57\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   58\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   59\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   60\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5780523255813954   61\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   62\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.5780523255813954   63\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7445736434108526   64\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7486918604651163   65\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7390988372093024   66\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7855135658914729   67\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7901647286821707   68\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.7784399224806201   69\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8190891472868216   70\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8191860465116279   71\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8066375968992249   72\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8540697674418605   73\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8573158914728684   74\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8436046511627907   75\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8718992248062015   76\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8658430232558139   77\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8731589147286822   78\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8718023255813954   79\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.8711240310077519   80\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n",
      "0.873546511627907   81\n",
      "0.8825096899224805\n",
      "{'loss': 'exp', 'learning_rate': 0.1, 'n_estimators': 15, 'colsample': 1.0, 'subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "for loss1 in loss:\n",
    "    for learn1 in learn:\n",
    "        for colsample1 in colsample:\n",
    "            for subsample1 in subsample:\n",
    "                res = 0.0\n",
    "                ind+=1\n",
    "                for train, test in skf.split(X, y):\n",
    "                    my_clf1 = MyGradientBoostingClassifier(loss=loss1, learning_rate=learn1, \n",
    "                                                        n_estimators=best_est,\n",
    "                                                        colsample=colsample1, \n",
    "                                                        subsample=subsample1)\n",
    "                    my_clf1.fit(X[train], y[train])\n",
    "                    temp = my_clf1.predict(X[test])\n",
    "                    res = res + accuracy_score(y[test], temp)\n",
    "                print(res/5.0, \" \", ind)\n",
    "                if (res/5.0) > best_score:\n",
    "                    best_score = res/5.0\n",
    "                    best_params['loss'] = loss1\n",
    "                    best_params['learning_rate'] = learn1\n",
    "                    best_params['colsample'] = colsample1\n",
    "                    best_params['subsample'] = subsample1\n",
    "                print(best_score)\n",
    "                print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты, полученные на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'exp',\n",
       " 'learning_rate': 0.1,\n",
       " 'n_estimators': 15,\n",
       " 'colsample': 1.0,\n",
       " 'subsample': 0.75}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825096899224805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9001937984496124\n",
      "0.8825096899224806\n",
      "0.8965600775193798\n",
      "0.8783914728682171\n",
      "0.9004360465116279\n",
      "BooBag result:  0.8916182170542637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier(**best_params)\n",
    "    my_clf1.fit(X[train], y[train], base_model = RandomForestRegressor)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"BooBag result: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b8640bc4f24796aea2c82da56e6421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bfe8025b20427dbe9fb69b26dd4d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbedab675f14f93af27bfd6b56f4ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bfb5a8022f4b7fba62790eb63c9517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35ec61b47d8452cb22b75564b319dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BagBoo result:  0.8526647286821705\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "N = 50\n",
    "for train, test in skf.split(X, y):\n",
    "    res1 = 0\n",
    "    for i in tqdm_notebook(range(N)):\n",
    "        my_clf1 = MyGradientBoostingClassifier(**best_params)\n",
    "        obj = np.random.choice(X[train].shape[0], X[train].shape[0] // N)\n",
    "        my_clf1.fit(X[train][obj], y[train][obj])\n",
    "        temp = my_clf1.predict(X[test])\n",
    "        res1 = res1 + temp\n",
    "    res1 = res1 / N\n",
    "    resN = np.around(res1).astype('int')\n",
    "    res = res + accuracy_score(y[test], resN)\n",
    "print(\"BagBoo result: \", res/5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании Random Forest в качестве базовой модели скор увеличился - Random Forest лучше адаптируется под данные.\n",
    "BagBoo не улучшил результаты, возможно, для него необходимо отдельно подбирать параметры на валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827519379844961\n",
      "0.8846899224806202\n",
      "0.8921996124031008\n",
      "0.8733042635658915\n",
      "0.8834786821705426\n",
      "Score LinearRegression:  0.8832848837209303\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = LinearRegression)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score LinearRegression: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8396317829457365\n",
      "0.8299418604651163\n",
      "0.8316375968992248\n",
      "0.8217054263565892\n",
      "0.8238856589147286\n",
      "Score LogisticRegression:  0.8293604651162791\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = LogisticRegression)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score LogisticRegression: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374515503875969\n",
      "0.8328488372093024\n",
      "0.8284883720930233\n",
      "0.8318798449612403\n",
      "0.844718992248062\n",
      "Score DecisionTreeRegressor:  0.835077519379845\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = DecisionTreeRegressor)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score DecisionTreeRegressor: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8318798449612403\n",
      "0.8323643410852714\n",
      "0.8357558139534884\n",
      "0.8287306201550387\n",
      "0.8355135658914729\n",
      "Score DecisionTreeClassifier:  0.8328488372093024\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = DecisionTreeClassifier)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score DecisionTreeClassifier: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8069282945736435\n",
      "0.8502906976744186\n",
      "0.8040213178294574\n",
      "0.8231589147286822\n",
      "0.8204941860465116\n",
      "Score SGDClassifier:  0.8209786821705427\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = SGDClassifier)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score SGDClassifier: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8459302325581395\n",
      "0.8548934108527132\n",
      "0.7877906976744186\n",
      "0.8250968992248062\n",
      "0.7902131782945736\n",
      "Score LinearSVC:  0.8207848837209302\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = LinearSVC)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score LinearSVC: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657945736434108\n",
      "0.8791182170542635\n",
      "0.875484496124031\n",
      "0.8817829457364341\n",
      "0.8689437984496124\n",
      "Score SVC:  0.8742248062015502\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = SVC)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score SVC: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8856589147286822\n",
      "0.8931686046511628\n",
      "0.8868701550387597\n",
      "0.8800872093023255\n",
      "0.8885658914728682\n",
      "Score RandomForestRegressor:  0.8868701550387599\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = RandomForestRegressor)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score RandomForestRegressor: \", res/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849321705426356\n",
      "0.8905038759689923\n",
      "0.8842054263565892\n",
      "0.8892926356589147\n",
      "0.8924418604651163\n",
      "Score RandomForestClassifier:  0.8882751937984497\n"
     ]
    }
   ],
   "source": [
    "res = 0.0\n",
    "for train, test in skf.split(X, y):\n",
    "    my_clf1 = MyGradientBoostingClassifier()\n",
    "    my_clf1.fit(X[train], y[train], init_model = RandomForestClassifier)\n",
    "    temp = my_clf1.predict(X[test])\n",
    "    res = res + accuracy_score(y[test], temp)\n",
    "    print(accuracy_score(y[test], temp))\n",
    "print(\"Score RandomForestClassifier: \", res/5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество решения при использовании RandomForestClassifier улучшилось - модель дает в начале более точное решение, проще исправлять ошибки на следующих итерациях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
